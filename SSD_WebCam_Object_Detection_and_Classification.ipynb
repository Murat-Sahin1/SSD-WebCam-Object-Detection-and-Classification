{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmjuSr81uW0r",
        "outputId": "1ae2a19f-f59e-4abd-a307-5c9333d65913",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:35:32.636866Z",
          "iopub.execute_input": "2023-01-25T00:35:32.638035Z",
          "iopub.status.idle": "2023-01-25T00:35:55.532476Z",
          "shell.execute_reply.started": "2023-01-25T00:35:32.637922Z",
          "shell.execute_reply": "2023-01-25T00:35:55.530745Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 80774, done.\u001b[K\n",
            "remote: Counting objects: 100% (311/311), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 80774 (delta 187), reused 230 (delta 139), pack-reused 80463\u001b[K\n",
            "Receiving objects: 100% (80774/80774), 594.66 MiB | 17.33 MiB/s, done.\n",
            "Resolving deltas: 100% (57540/57540), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd models/research && protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "p5sfcdKCu3NQ",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:38:40.184265Z",
          "iopub.execute_input": "2023-01-25T00:38:40.184652Z",
          "iopub.status.idle": "2023-01-25T00:38:41.214042Z",
          "shell.execute_reply.started": "2023-01-25T00:38:40.184611Z",
          "shell.execute_reply": "2023-01-25T00:38:41.212404Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd models/research && \\\n",
        "    cp object_detection/packages/tf2/setup.py . && \\\n",
        "    python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0nsqT2DvWSx",
        "outputId": "4e1ef41e-eb89-460f-81b3-57383af07f97",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:38:57.154386Z",
          "iopub.execute_input": "2023-01-25T00:38:57.154780Z",
          "iopub.status.idle": "2023-01-25T00:41:02.192861Z",
          "shell.execute_reply.started": "2023-01-25T00:38:57.154746Z",
          "shell.execute_reply": "2023-01-25T00:41:02.191596Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.1)\n",
            "Collecting tensorflow~=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.3.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.4.0)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.30.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Collecting keras\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21919980 sha256=b9364a8d9bcf25f668a3717c0541cefa1cccf0d9008269695f90e578304ff380\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1x6g6elt/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=9497584b2e6205a7609c8be52b90ee8a5d0194b3e594bfa23c2e46e835e25b16\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=f25173f0fe8fb182d58a2034d6f27b7c1aedf8e95424d0c492729c1733020e2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=ebc81e2f182527cb014aff0b8e2578ce4685fc3755989643b721df62dd3cf41e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=58638939acd5121dfbca0ba112a6c9e27e37f58fb0e5480cd871012afa53b3ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, flatbuffers, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, tensorflow-estimator, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, keras, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, tensorflow_io, sacrebleu, hdfs, tensorflow-addons, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.29.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.29.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.29.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed apache-beam-2.44.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 flatbuffers-23.1.21 hdfs-2.7.0 immutabledict-2.2.3 keras-2.11.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.5 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-addons-0.19.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.30.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Kovv0ngDnx",
        "outputId": "c6ff279b-ab98-4db3-e954-21e38ed62a0c",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:41:54.597768Z",
          "iopub.execute_input": "2023-01-25T00:41:54.598515Z",
          "iopub.status.idle": "2023-01-25T00:42:05.770646Z",
          "shell.execute_reply.started": "2023-01-25T00:41:54.598470Z",
          "shell.execute_reply": "2023-01-25T00:42:05.769438Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import object_detection\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SrM9gAPWvkZA",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:10.965703Z",
          "iopub.execute_input": "2023-01-25T00:42:10.966141Z",
          "iopub.status.idle": "2023-01-25T00:42:14.855246Z",
          "shell.execute_reply.started": "2023-01-25T00:42:10.966103Z",
          "shell.execute_reply": "2023-01-25T00:42:14.854111Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "IZCNiFBov6T2",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:31.245091Z",
          "iopub.execute_input": "2023-01-25T00:42:31.245489Z",
          "iopub.status.idle": "2023-01-25T00:42:31.250521Z",
          "shell.execute_reply.started": "2023-01-25T00:42:31.245459Z",
          "shell.execute_reply": "2023-01-25T00:42:31.249476Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://lazyprogrammer.me/cnn_class2_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BaPpwvfv_U2",
        "outputId": "0980ff60-04bb-4257-b265-3264b6f0e3e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-25 23:18:18--  https://lazyprogrammer.me/cnn_class2_videos.zip\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3030::ac43:d5a6, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2073140 (2.0M) [application/zip]\n",
            "Saving to: ‘cnn_class2_videos.zip’\n",
            "\n",
            "cnn_class2_videos.z 100%[===================>]   1.98M  4.00MB/s    in 0.5s    \n",
            "\n",
            "2023-01-25 23:18:19 (4.00 MB/s) - ‘cnn_class2_videos.zip’ saved [2073140/2073140]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cnn_class2_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMXqjNLBwR8p",
        "outputId": "9b76b194-d022-43c7-ddaf-3c1fea4b1bca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cnn_class2_videos.zip\n",
            "  inflating: catdog.mp4              \n",
            "  inflating: safari.mp4              \n",
            "  inflating: traffic.mp4             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY6JSTuCwViW",
        "outputId": "31b38c2a-6fb5-46db-885b-363b33855e82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "catdog.mp4  cnn_class2_videos.zip  models  safari.mp4  sample_data  traffic.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VIDEOS = ['catdog', 'safari', 'traffic']"
      ],
      "metadata": {
        "id": "iw3O3RdtwaH4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pre-trained Object Detector\n",
        "Tensorflow 2 Detection Model Zoo, there is a tradeoff between speed and accuracy. There are different models containing different algorithms. We'll use SSD for this context. Also, our file comes as .tar, we untar it via options."
      ],
      "metadata": {
        "id": "OPAKXzFqw7L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
        "\n",
        "PATH_TO_MODEL_DIR = tf.keras.utils.get_file(\n",
        "    fname = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8',\n",
        "    origin = url,\n",
        "    untar = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNTE0huHwtCv",
        "outputId": "e5bf4df6-22a2-4c0f-b415-03a4a2d8565d",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:40.603852Z",
          "iopub.execute_input": "2023-01-25T00:42:40.606500Z",
          "iopub.status.idle": "2023-01-25T00:42:46.162504Z",
          "shell.execute_reply.started": "2023-01-25T00:42:40.606464Z",
          "shell.execute_reply": "2023-01-25T00:42:46.161430Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "386527459/386527459 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Path to our model"
      ],
      "metadata": {
        "id": "Kk1gDOLqw05A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_MODEL_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6__15Iwrw2cH",
        "outputId": "3e77663d-652d-4723-9bfc-91aff1e7be8e",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:49.547503Z",
          "iopub.execute_input": "2023-01-25T00:42:49.547884Z",
          "iopub.status.idle": "2023-01-25T00:42:49.556824Z",
          "shell.execute_reply.started": "2023-01-25T00:42:49.547840Z",
          "shell.execute_reply": "2023-01-25T00:42:49.555853Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download our labels\n",
        "Label files can be found here:\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection/data\n",
        "You probably won't need these since Object Detection Zoo contains only models trained on COCO. COCO is a large-scale object detection, segmentation, and captioning dataset."
      ],
      "metadata": {
        "id": "ZW9AJmzwxEJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "PATH_TO_LABELS = tf.keras.utils.get_file(\n",
        "    fname = 'mscoco_label_map.pbtxt',\n",
        "    origin = url,\n",
        "    untar = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEUvY0cFxKbe",
        "outputId": "a3e7f6cb-39a5-4791-f526-e4a5422b7cf4",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:51.675580Z",
          "iopub.execute_input": "2023-01-25T00:42:51.675981Z",
          "iopub.status.idle": "2023-01-25T00:42:51.861034Z",
          "shell.execute_reply.started": "2023-01-25T00:42:51.675947Z",
          "shell.execute_reply": "2023-01-25T00:42:51.859943Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
            "5056/5056 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Path to the labels"
      ],
      "metadata": {
        "id": "_SDGW8FmxQS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TDGwqyH9xS_-",
        "outputId": "782cdaac-c430-4223-a640-882287c30a38",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:54.124258Z",
          "iopub.execute_input": "2023-01-25T00:42:54.124639Z",
          "iopub.status.idle": "2023-01-25T00:42:54.510759Z",
          "shell.execute_reply.started": "2023-01-25T00:42:54.124607Z",
          "shell.execute_reply": "2023-01-25T00:42:54.509302Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/mscoco_label_map.pbtxt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {PATH_TO_LABELS}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MkNs_OaxVY2",
        "outputId": "0b670863-36da-45a5-cd53-b775ffdb2fb1",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:55.811823Z",
          "iopub.execute_input": "2023-01-25T00:42:55.812556Z",
          "iopub.status.idle": "2023-01-25T00:42:56.800510Z",
          "shell.execute_reply.started": "2023-01-25T00:42:55.812521Z",
          "shell.execute_reply": "2023-01-25T00:42:56.799321Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item {\n",
            "  name: \"/m/01g317\"\n",
            "  id: 1\n",
            "  display_name: \"person\"\n",
            "}\n",
            "item {\n",
            "  name: \"/m/0199g\"\n",
            "  id: 2\n",
            "  display_name: \"bicycle\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in the Model\n",
        "This is what will give us a neural network, which we will use to make predictions."
      ],
      "metadata": {
        "id": "UZE0N7eHxaWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\" \n",
        "\n",
        "print('Loading model', end = '')\n",
        "start_time = time.time()\n",
        "\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL) # load in the model, \n",
        "# returns a detection function which could be used on object detection\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done. Took {} seconds'.format(elapsed_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFW2jKaexYsK",
        "outputId": "10b2aa76-a24c-40eb-f896-a19db943d435",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:42:58.774937Z",
          "iopub.execute_input": "2023-01-25T00:42:58.775994Z",
          "iopub.status.idle": "2023-01-25T00:43:22.364111Z",
          "shell.execute_reply.started": "2023-01-25T00:42:58.775933Z",
          "shell.execute_reply": "2023-01-25T00:43:22.362953Z"
        },
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading modelDone. Took 31.178539991378784 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in our labels\n",
        "Loading our labels. These are currently stored in a file. This function reads from a file. Call the function, create category index from label map."
      ],
      "metadata": {
        "id": "kG_LI7cgx0cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(\n",
        "    PATH_TO_LABELS,\n",
        "    use_display_name = True\n",
        ")"
      ],
      "metadata": {
        "id": "JxyYpdu3xZ-E",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:43:24.558255Z",
          "iopub.execute_input": "2023-01-25T00:43:24.558662Z",
          "iopub.status.idle": "2023-01-25T00:43:24.571547Z",
          "shell.execute_reply.started": "2023-01-25T00:43:24.558630Z",
          "shell.execute_reply": "2023-01-25T00:43:24.570153Z"
        },
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index"
      ],
      "metadata": {
        "id": "WQhu1yBAx5Qq",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fed03c-6353-4c5d-9302-261221b45725"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'id': 1, 'name': 'person'},\n",
              " 2: {'id': 2, 'name': 'bicycle'},\n",
              " 3: {'id': 3, 'name': 'car'},\n",
              " 4: {'id': 4, 'name': 'motorcycle'},\n",
              " 5: {'id': 5, 'name': 'airplane'},\n",
              " 6: {'id': 6, 'name': 'bus'},\n",
              " 7: {'id': 7, 'name': 'train'},\n",
              " 8: {'id': 8, 'name': 'truck'},\n",
              " 9: {'id': 9, 'name': 'boat'},\n",
              " 10: {'id': 10, 'name': 'traffic light'},\n",
              " 11: {'id': 11, 'name': 'fire hydrant'},\n",
              " 13: {'id': 13, 'name': 'stop sign'},\n",
              " 14: {'id': 14, 'name': 'parking meter'},\n",
              " 15: {'id': 15, 'name': 'bench'},\n",
              " 16: {'id': 16, 'name': 'bird'},\n",
              " 17: {'id': 17, 'name': 'cat'},\n",
              " 18: {'id': 18, 'name': 'dog'},\n",
              " 19: {'id': 19, 'name': 'horse'},\n",
              " 20: {'id': 20, 'name': 'sheep'},\n",
              " 21: {'id': 21, 'name': 'cow'},\n",
              " 22: {'id': 22, 'name': 'elephant'},\n",
              " 23: {'id': 23, 'name': 'bear'},\n",
              " 24: {'id': 24, 'name': 'zebra'},\n",
              " 25: {'id': 25, 'name': 'giraffe'},\n",
              " 27: {'id': 27, 'name': 'backpack'},\n",
              " 28: {'id': 28, 'name': 'umbrella'},\n",
              " 31: {'id': 31, 'name': 'handbag'},\n",
              " 32: {'id': 32, 'name': 'tie'},\n",
              " 33: {'id': 33, 'name': 'suitcase'},\n",
              " 34: {'id': 34, 'name': 'frisbee'},\n",
              " 35: {'id': 35, 'name': 'skis'},\n",
              " 36: {'id': 36, 'name': 'snowboard'},\n",
              " 37: {'id': 37, 'name': 'sports ball'},\n",
              " 38: {'id': 38, 'name': 'kite'},\n",
              " 39: {'id': 39, 'name': 'baseball bat'},\n",
              " 40: {'id': 40, 'name': 'baseball glove'},\n",
              " 41: {'id': 41, 'name': 'skateboard'},\n",
              " 42: {'id': 42, 'name': 'surfboard'},\n",
              " 43: {'id': 43, 'name': 'tennis racket'},\n",
              " 44: {'id': 44, 'name': 'bottle'},\n",
              " 46: {'id': 46, 'name': 'wine glass'},\n",
              " 47: {'id': 47, 'name': 'cup'},\n",
              " 48: {'id': 48, 'name': 'fork'},\n",
              " 49: {'id': 49, 'name': 'knife'},\n",
              " 50: {'id': 50, 'name': 'spoon'},\n",
              " 51: {'id': 51, 'name': 'bowl'},\n",
              " 52: {'id': 52, 'name': 'banana'},\n",
              " 53: {'id': 53, 'name': 'apple'},\n",
              " 54: {'id': 54, 'name': 'sandwich'},\n",
              " 55: {'id': 55, 'name': 'orange'},\n",
              " 56: {'id': 56, 'name': 'broccoli'},\n",
              " 57: {'id': 57, 'name': 'carrot'},\n",
              " 58: {'id': 58, 'name': 'hot dog'},\n",
              " 59: {'id': 59, 'name': 'pizza'},\n",
              " 60: {'id': 60, 'name': 'donut'},\n",
              " 61: {'id': 61, 'name': 'cake'},\n",
              " 62: {'id': 62, 'name': 'chair'},\n",
              " 63: {'id': 63, 'name': 'couch'},\n",
              " 64: {'id': 64, 'name': 'potted plant'},\n",
              " 65: {'id': 65, 'name': 'bed'},\n",
              " 67: {'id': 67, 'name': 'dining table'},\n",
              " 70: {'id': 70, 'name': 'toilet'},\n",
              " 72: {'id': 72, 'name': 'tv'},\n",
              " 73: {'id': 73, 'name': 'laptop'},\n",
              " 74: {'id': 74, 'name': 'mouse'},\n",
              " 75: {'id': 75, 'name': 'remote'},\n",
              " 76: {'id': 76, 'name': 'keyboard'},\n",
              " 77: {'id': 77, 'name': 'cell phone'},\n",
              " 78: {'id': 78, 'name': 'microwave'},\n",
              " 79: {'id': 79, 'name': 'oven'},\n",
              " 80: {'id': 80, 'name': 'toaster'},\n",
              " 81: {'id': 81, 'name': 'sink'},\n",
              " 82: {'id': 82, 'name': 'refrigerator'},\n",
              " 84: {'id': 84, 'name': 'book'},\n",
              " 85: {'id': 85, 'name': 'clock'},\n",
              " 86: {'id': 86, 'name': 'vase'},\n",
              " 87: {'id': 87, 'name': 'scissors'},\n",
              " 88: {'id': 88, 'name': 'teddy bear'},\n",
              " 89: {'id': 89, 'name': 'hair drier'},\n",
              " 90: {'id': 90, 'name': 'toothbrush'}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper function\n",
        "Takes input of an image file and turn that into a numpy array.\n",
        "Returns a 3 dimensional object which is (im_height, im_width, 3),\n",
        "height by weight by color."
      ],
      "metadata": {
        "id": "c2nePPuHfkmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(current_image):\n",
        "    return np.array(PIL.Image.open(current_image))  "
      ],
      "metadata": {
        "id": "n6Nz5Tnefic2",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:43:36.342424Z",
          "iopub.execute_input": "2023-01-25T00:43:36.342783Z",
          "iopub.status.idle": "2023-01-25T00:43:36.347387Z",
          "shell.execute_reply.started": "2023-01-25T00:43:36.342753Z",
          "shell.execute_reply": "2023-01-25T00:43:36.346206Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taking single image as input, annotating it and returning\n",
        "Takes an input image. Loads it in. Runs the neural network, uses utilites to annotate the image with the neural network predictions. Most of the job is done by libraries."
      ],
      "metadata": {
        "id": "wgOF2zJdyEcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects_in_image(input_tensor):\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    # pop the entry for num_detections\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "\n",
        "    # filtering the detections from the item at number 0 to remaining items\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                 for key, value in detections.items()}\n",
        "    \n",
        "    # re-assign num-detections\n",
        "    detections['num_detections'] = num_detections\n",
        "    \n",
        "    # turning detection classes into integers\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections = image_np.copy()\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates = True,\n",
        "        max_boxes_to_draw = 200,\n",
        "        min_score_thresh = .30,\n",
        "        agnostic_mode = False\n",
        "    )\n",
        "\n",
        "    return image_np_with_detections"
      ],
      "metadata": {
        "id": "dYO6Z0ZlyCdH",
        "execution": {
          "iopub.status.busy": "2023-01-25T00:43:38.600251Z",
          "iopub.execute_input": "2023-01-25T00:43:38.600623Z",
          "iopub.status.idle": "2023-01-25T00:43:38.609408Z",
          "shell.execute_reply.started": "2023-01-25T00:43:38.600590Z",
          "shell.execute_reply": "2023-01-25T00:43:38.608219Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input"
      ],
      "metadata": {
        "id": "fiMVDcFoORRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "VtRaDX_4qfo-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to convert the JavaScript object into an OpenCV image"
      ],
      "metadata": {
        "id": "GcnCH8sLOMgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "DTRoJTrbrZ_v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting the stream and sending frames to the detection function"
      ],
      "metadata": {
        "id": "ri8owldaN7Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    image_np = js_to_image(js_reply[\"img\"])\n",
        "    print(type(image_np))\n",
        "   \n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.uint8)\n",
        "    \n",
        "    print('Detecting the objects...')\n",
        "    image_np_with_detections = detect_objects_in_image(input_tensor)\n",
        "    \n",
        "    # Display output\n",
        "    # cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    cv2_imshow(cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "aR03jHrXqfo_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}